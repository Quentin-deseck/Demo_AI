{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ecc7a0-48fa-4087-bf92-ed61bcd27110",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daecae30-35b2-4344-90e7-b13d4d1e777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9218e9f5-9462-4baa-8e04-944e4cdfa9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"meta-llama/llama-3.2-1b\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aed114d-ae54-4209-b9e8-a781dcb969e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491c33c0-4198-462f-8697-97aa9f51f021",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866a11ca-eb2a-4622-80be-ed996afbaf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./models\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6755bdc-dfb7-4ef4-a611-5120d82eef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_tokens=100):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(**inputs, max_new_tokens=max_tokens)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2991de-baa7-4659-9828-930c5dabbb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"Hello, how are you?\"\n",
    "response = generate_text(user_input)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e0cc1e-819f-4efe-b38e-4bdf5ed823fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=\"./models\")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir=\"./models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca4a396-317b-4b16-aeed-b2237873451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls ./models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242d7366-f1bf-4097-a235-7249224e3493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
